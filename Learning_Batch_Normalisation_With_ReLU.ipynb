{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvq201-_Jefn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuZZ80ZsLSjB",
        "outputId": "0da2bf6a-4bf0-4a5e-8f4c-68e84add5866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create and compile CNN model with BN\n",
        "def create_cnn():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape= (28,28,1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JHvWerXhLTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate(model, x_train, y_train, x_val, y_val, epochs=10):\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_val, y_val))\n",
        "    return history"
      ],
      "metadata": {
        "id": "6yHd0l3iLT23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(history, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WaSh6CjMLT55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the data for CNN\n",
        "\n",
        "x_train_mnist = x_train_mnist.reshape((60000, 28, 28, 1))\n",
        "x_test_mnist = x_test_mnist.reshape((10000, 28, 28, 1))"
      ],
      "metadata": {
        "id": "cxMi-zeQLT83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the CNN model\n",
        "model_mnist = create_cnn()\n",
        "\n",
        "# Train and evaluate the model\n",
        "history_mnist = train_and_evaluate(model_mnist, x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist, epochs=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3lK4KD-LT_n",
        "outputId": "d75bbc2c-8d60-4fce-aeb3-361227aba8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "1875/1875 [==============================] - 15s 7ms/step - loss: 0.1046 - accuracy: 0.9698 - val_loss: 0.0360 - val_accuracy: 0.9886\n",
            "Epoch 2/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.0288 - val_accuracy: 0.9905\n",
            "Epoch 3/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0280 - val_accuracy: 0.9911\n",
            "Epoch 4/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0324 - val_accuracy: 0.9899\n",
            "Epoch 5/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0339 - val_accuracy: 0.9896\n",
            "Epoch 6/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0561 - val_accuracy: 0.9811\n",
            "Epoch 7/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
            "Epoch 8/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
            "Epoch 9/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0280 - val_accuracy: 0.9928\n",
            "Epoch 10/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0301 - val_accuracy: 0.9929\n",
            "Epoch 11/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0263 - val_accuracy: 0.9928\n",
            "Epoch 12/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0265 - val_accuracy: 0.9926\n",
            "Epoch 13/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0285 - val_accuracy: 0.9923\n",
            "Epoch 14/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0355 - val_accuracy: 0.9917\n",
            "Epoch 15/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9909\n",
            "Epoch 16/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0273 - val_accuracy: 0.9933\n",
            "Epoch 17/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0282 - val_accuracy: 0.9921\n",
            "Epoch 18/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0306 - val_accuracy: 0.9928\n",
            "Epoch 19/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0305 - val_accuracy: 0.9926\n",
            "Epoch 20/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0375 - val_accuracy: 0.9905\n",
            "Epoch 21/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0338 - val_accuracy: 0.9923\n",
            "Epoch 22/42\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0371 - val_accuracy: 0.9922\n",
            "Epoch 23/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0286 - val_accuracy: 0.9940\n",
            "Epoch 24/42\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0336 - val_accuracy: 0.9923\n",
            "Epoch 25/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0309 - val_accuracy: 0.9929\n",
            "Epoch 26/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0249 - val_accuracy: 0.9934\n",
            "Epoch 27/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0481 - val_accuracy: 0.9904\n",
            "Epoch 28/42\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
            "Epoch 29/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0327 - val_accuracy: 0.9929\n",
            "Epoch 30/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0331 - val_accuracy: 0.9938\n",
            "Epoch 31/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0321 - val_accuracy: 0.9941\n",
            "Epoch 32/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0325 - val_accuracy: 0.9932\n",
            "Epoch 33/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0325 - val_accuracy: 0.9933\n",
            "Epoch 34/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0325 - val_accuracy: 0.9940\n",
            "Epoch 35/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0335 - val_accuracy: 0.9935\n",
            "Epoch 36/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
            "Epoch 37/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0393 - val_accuracy: 0.9925\n",
            "Epoch 38/42\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0423 - val_accuracy: 0.9919\n",
            "Epoch 39/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0419 - val_accuracy: 0.9918\n",
            "Epoch 40/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0382 - val_accuracy: 0.9922\n",
            "Epoch 41/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0324 - val_accuracy: 0.9927\n",
            "Epoch 42/42\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0392 - val_accuracy: 0.9921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization is a technique used in neural networks to improve training stability and accelerate convergence.One way it does this is by helping in stabilizing the training process by normalizing the input of each layer. This mitigates issues like vanishing or exploding gradients."
      ],
      "metadata": {
        "id": "c9jMyHicOWqq"
      }
    }
  ]
}